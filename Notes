kops create cluster --name=kubevpro.tugu.live \
--state=s3://vprofile-kops-state1994 --zones=ap-southeast-1a,ap-southeast-1b \
--node-count=2 --node-size=t3.small --master-size=t3.medium --dns-zone=kubevpro.tugu.live \
--node-volume-size=8 --master-volume-size=8 


kops update cluster --name kubevpro.tugu.live --state=s3://vprofile-kops-state1994 --yes --admin

kops validate cluster --state=s3://vprofile-kops-state1994 --wait 10m
kops delete cluster --name=kubevpro.tugu.live --state=s3://vprofile-kops-state1994 --yes









kops create cluster --name=kubevpro.tugu.live --state=s3://vprofile-kops-state1994 --zones=ap-southeast-1a,ap-southeast-1b --node-count=2 --node-size=t2.small --master-size=t2.small --dns-zone=kubevpro.tugu.live


kops update cluster --name kubevpro.tugu.live --state=s3://vprofile-kops-state1994 --yes --admin

kops validate cluster --state=s3://vprofile-kops-state1994 --wait 10m



kops delete cluster --name=kubevpro.tugu.live --state=s3://vprofile-kops-state1994 --yes


===================================================================================================================================================

tgadmin
https://681164955908.signin.aws.amazon.com/console

kops create cluster --name=kubevpro.tugu.live \
--state=s3://vprofile-kops-state1994 --zones=ap-southeast-1a,ap-southeast-1b \
--node-count=2 --node-size=t3.small --master-size=t3.medium --dns-zone=kubevpro.tugu.live \
--node-volume-size=8 --master-volume-size=8 

kops update cluster --name kubevpro.tugu.live --state=s3://vprofile-kops-state1994 --yes --admin

Suggestions:
 * validate cluster: kops validate cluster --wait 10m
 * list nodes: kubectl get nodes --show-labels
 * ssh to a control-plane node: ssh -i ~/.ssh/id_rsa ubuntu@api.kubevpro.tugu.live
 * the ubuntu user is specific to Ubuntu. If not using Ubuntu please use the appropriate user based on your OS.
 * read about installing addons at: https://kops.sigs.k8s.io/addons.

kops validate cluster --state=s3://vprofile-kops-state1994 --wait 10m


-- Create volume

aws ec2 create-volume --availability-zone=ap-southeast-1a --size=3 --volume-type=gp2

{
    "AvailabilityZone": "ap-southeast-1a",
    "CreateTime": "2023-06-27T03:17:25.000Z",
    "Encrypted": false,
    "Size": 3,
    "SnapshotId": "",
    "State": "creating",
    "VolumeId": "vol-064d47bf311940961",
    "Iops": 100,
    "Tags": [],
    "VolumeType": "gp2",
    "MultiAttachEnabled": false
}


kubectl get nodes --show-labels

kubectl describe node i-09b0ab5579f6a295c

kubectl describe node i-09b0ab5579f6a295c | grep ap-southeast-1b

kubectl describe node i-0d7518bdd973758f1 | grep ap-southeast-1a


kubectl label nodes i-09b0ab5579f6a295c zone=ap-southeast-1b
kubectl label nodes i-0d7518bdd973758f1 zone=ap-southeast-1a


=========================================================================================================
kops get ig --name=kubevpro.tugu.live --state=s3://vprofile-kops-state1994 -o yaml

kops edit ig control-plane-ap-southeast-1a --name=kubevpro.tugu.live --state=s3://vprofile-kops-state1994
kops edit ig nodes-ap-southeast-1a --name=kubevpro.tugu.live --state=s3://vprofile-kops-state1994
kops edit ig nodes-ap-southeast-1b --name=kubevpro.tugu.live --state=s3://vprofile-kops-state1994

kops update cluster --name kubevpro.tugu.live --state=s3://vprofile-kops-state1994 --yes --admin

kops validate cluster --name kubevpro.tugu.live --state=s3://vprofile-kops-state1994 --wait 10m
=========================================================================================================
